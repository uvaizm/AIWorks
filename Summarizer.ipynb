{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uvaizm/AIWorks/blob/master/Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JsBEsZ3hpcZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "b55ddd74-938b-4db6-a80d-7e6391d440f8"
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 14.9MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/cb/1bbd133fcdf24849fd7a1e5e1492e029a45d59cff75ad2b53d456724940b/boto3-1.9.51-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 23.1MB/s \n",
            "\u001b[?25hCollecting botocore<1.13.0,>=1.12.51 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/238a4cbdcd85d00c3abe2f2122ea30d303ec4ea14c833ccfbebb68760908/botocore-1.12.51-py2.py3-none-any.whl (4.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.9MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.51->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Collecting docutils>=0.10 (from botocore<1.13.0,>=1.12.51->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 25.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.51 botocore-1.12.51 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2stVWDMLsjJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Nov 26 16:06:36 2018\n",
        "\n",
        "@author: muvaiz\n",
        "\"\"\"\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import collections\n",
        "import pickle\n",
        "import numpy as np\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "train_article_path =\"train.article.txt\"\n",
        "train_title_path =\"train.title.txt\"\n",
        "valid_article_path =\"valid.article.filter.txt\"\n",
        "valid_title_path =\"valid.title.filter.txt\"\n",
        "\n",
        "#to clean sentence\n",
        "def clean_str(sentence):\n",
        "    sentence=re.sub(\"[#.]+\",\"#\",sentence)\n",
        "    return sentence\n",
        "\n",
        "#read each line from given file and will pass it to clean_str function for cleaning sentence. \"toy\" flag will be used for optimization\n",
        "def get_text_list(data_path,toy):\n",
        "    with open(data_path,'r',encoding=\"utf-8\") as f:\n",
        "        if not toy:\n",
        "            return([clean_str(x.strip()) for x in f.readlines()])\n",
        "        else:\n",
        "            return([clean_str(x.strip()) for x in f.readlines()][:50000])\n",
        "            \n",
        "            \n",
        "#to build a dictionary containing each unique word from the training data and respective value\n",
        "#returns formed word vs number dictionary, inverse of it, max article length,max summary length\n",
        "def build_dict(step,toy=False):\n",
        "    if step==\"train\":\n",
        "        train_article_list=get_text_list(train_article_path,toy)\n",
        "        train_title_list=get_text_list(train_title_path,toy)\n",
        "        \n",
        "        train_list=train_article_list+train_title_list\n",
        "        \n",
        "        words=list()\n",
        "        \n",
        "        for sentence in train_list:\n",
        "            for word in word_tokenize(sentence):\n",
        "                words.append(word)\n",
        "                \n",
        "        word_counter=collections.Counter(words).most_common()\n",
        "        word_dict=dict()\n",
        "        word_dict[\"<padding>\"]=0\n",
        "        word_dict[\"<unk>\"]=1\n",
        "        word_dict[\"<s>\"]=2\n",
        "        word_dict[\"</s>\"]=3\n",
        "        \n",
        "        for word,_ in word_counter:\n",
        "            word_dict[word]=len(word_dict)\n",
        "            \n",
        "        with open(\"word_dict.pickle\",\"wb\") as f:\n",
        "            pickle.dump(word_dict,f)\n",
        "            \n",
        "    elif step==\"valid\":\n",
        "        with open(\"word_dict.pickle\",\"rb\") as f:\n",
        "            word_dict=pickle.load(f)\n",
        "            \n",
        "    reversed_dict = dict(zip(word_dict.values(),word_dict.keys()))\n",
        "    \n",
        "    article_max_len=50\n",
        "    summary_max_len=15\n",
        "    \n",
        "    return word_dict,reversed_dict,article_max_len,summary_max_len\n",
        "\n",
        "def build_dataset(step,word_dict,article_max_len,summary_max_len,toy=False):\n",
        "    if step==\"train\":\n",
        "        article_list=get_text_list(train_article_path,toy)\n",
        "        title_list=get_text_list(train_title_path,toy)\n",
        "    elif step==\"valid\":\n",
        "        article_list=get_text_list(valid_article_path,toy)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    \n",
        "    #sample output of sentence_with_word_lists_per_sent : [[\"I\",\"am\",\"a\",\"boy\"],[\"I\",\"like\",\"rain\"]]\n",
        "    sentences_with_word_lists_per_sent=[word_tokenize(sentence) for sentence in article_list]\n",
        "    \n",
        "    #sample output of sentence_with_word_lists_per_sent : [[\"101\",\"21\",\"343\",\"711\"],[\"100\",\"234\",\"1526\"]]\n",
        "    sentences_with_word_vector_lists_per_sent=[[word_dict.get(word,word_dict[\"<unk>\"]) for word in sentence] for sentence in sentences_with_word_lists_per_sent]\n",
        "                                                              \n",
        "    truncated_word_vector_lists_per_sent=[sentence[:article_max_len] for sentence in sentences_with_word_vector_lists_per_sent]\n",
        "    output_word_vector_lists=[sentence + (article_max_len - len(sentence)) * [word_dict[\"<padding>\"]] for sentence in truncated_word_vector_lists_per_sent]\n",
        "                                                              \n",
        "    if step==\"valid\":\n",
        "        return output_word_vector_lists\n",
        "    else:\n",
        "        title_with_word_lists_per_sent = [word_tokenize(sentence) for sentence in title_list]\n",
        "        title_with_word_vector_lists_per_sent=[[word_dict.get(word,word_dict[\"<unk>\"]) for word in sentence] for sentence in title_with_word_lists_per_sent]\n",
        "        output_title_vector_lists=[sentence[:(summary_max_len-1)]for sentence in title_with_word_vector_lists_per_sent]\n",
        "        return(output_word_vector_lists,output_title_vector_lists)\n",
        "        \n",
        "def batch_iter(inputs, outputs, batch_size, num_epochs):\n",
        "    inputs = np.array(inputs)\n",
        "    outputs = np.array(outputs)\n",
        "\n",
        "    num_batches_per_epoch = (len(inputs) - 1) // batch_size + 1\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_num in range(num_batches_per_epoch):\n",
        "            start_index = batch_num * batch_size\n",
        "            end_index = min((batch_num + 1) * batch_size, len(inputs))\n",
        "            yield inputs[start_index:end_index], outputs[start_index:end_index]\n",
        "            \n",
        "def get_init_embedding(reversed_dict,embedding_size):\n",
        "    glove_file=\"glove.6B.50d.txt\"\n",
        "    word2vec_file=get_tmpfile(\"word2vec_format.vec\")\n",
        "    glove2word2vec(glove_file,word2vec_file)\n",
        "    print(\"Loading Glove vectors...\")\n",
        "    word_vectors = KeyedVectors.load_word2vec_format(word2vec_file)\n",
        "    \n",
        "    word_vec_list = list()\n",
        "    \n",
        "    for _,word in sorted(reversed_dict.items()):\n",
        "        try:\n",
        "            word_vec = word_vectors.word_vec(word)\n",
        "        except KeyError:\n",
        "            word_vec=np.zeros([embedding_size],dtype=np.float32)\n",
        "            \n",
        "        word_vec_list.append(word_vec)\n",
        "        \n",
        "    word_vec_list[2] = np.random.normal(0, 1, embedding_size)\n",
        "    word_vec_list[3] = np.random.normal(0, 1, embedding_size)\n",
        "    \n",
        "    return(np.array(word_vec_list))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXf-_8Gus5ar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Nov 26 18:36:30 2018\n",
        "\n",
        "@author: muvaiz\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "#from utils import get_init_embedding\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "    def __init__(self, reversed_dict, article_max_len, summary_max_len, args, forward_only=False):\n",
        "        self.vocabulary_size = len(reversed_dict)\n",
        "        self.embedding_size = args.embedding_size\n",
        "        self.num_hidden = args.num_hidden\n",
        "        self.num_layers = args.num_layers\n",
        "        self.learning_rate = args.learning_rate\n",
        "        self.beam_width = args.beam_width\n",
        "        if not forward_only:\n",
        "            self.keep_prob = args.keep_prob\n",
        "        else:\n",
        "            self.keep_prob = 1.0\n",
        "        self.cell = tf.nn.rnn_cell.BasicLSTMCell\n",
        "        with tf.variable_scope(\"decoder/projection\"):\n",
        "            self.projection_layer = tf.layers.Dense(self.vocabulary_size, use_bias=False)\n",
        "\n",
        "        self.batch_size = tf.placeholder(tf.int32, (), name=\"batch_size\")\n",
        "        self.X = tf.placeholder(tf.int32, [None, article_max_len])\n",
        "        self.X_len = tf.placeholder(tf.int32, [None])\n",
        "        self.decoder_input = tf.placeholder(tf.int32, [None, summary_max_len])\n",
        "        self.decoder_len = tf.placeholder(tf.int32, [None])\n",
        "        self.decoder_target = tf.placeholder(tf.int32, [None, summary_max_len])\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "        with tf.name_scope(\"embedding\"):\n",
        "            if not forward_only and args.glove:\n",
        "                \n",
        "                init_embeddings = tf.constant(get_init_embedding(reversed_dict, self.embedding_size),dtype=tf.float32)\n",
        "            else:\n",
        "                init_embeddings = tf.random_uniform([self.vocabulary_size, self.embedding_size], -1.0, 1.0)\n",
        "            self.embeddings = tf.get_variable(\"embeddings\", initializer=init_embeddings)\n",
        "            self.encoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.X), perm=[1, 0, 2])\n",
        "            self.decoder_emb_inp = tf.transpose(tf.nn.embedding_lookup(self.embeddings, self.decoder_input), perm=[1, 0, 2])\n",
        "\n",
        "        with tf.name_scope(\"encoder\"):\n",
        "            fw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n",
        "            bw_cells = [self.cell(self.num_hidden) for _ in range(self.num_layers)]\n",
        "            fw_cells = [rnn.DropoutWrapper(cell) for cell in fw_cells]\n",
        "            bw_cells = [rnn.DropoutWrapper(cell) for cell in bw_cells]\n",
        "\n",
        "            encoder_outputs, encoder_state_fw, encoder_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
        "                fw_cells, bw_cells, self.encoder_emb_inp,\n",
        "                sequence_length=self.X_len, time_major=True, dtype=tf.float32)\n",
        "            self.encoder_output = tf.concat(encoder_outputs, 2)\n",
        "            encoder_state_c = tf.concat((encoder_state_fw[0].c, encoder_state_bw[0].c), 1)\n",
        "            encoder_state_h = tf.concat((encoder_state_fw[0].h, encoder_state_bw[0].h), 1)\n",
        "            self.encoder_state = rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
        "\n",
        "        with tf.name_scope(\"decoder\"), tf.variable_scope(\"decoder\") as decoder_scope:\n",
        "            decoder_cell = self.cell(self.num_hidden * 2)\n",
        "\n",
        "            if not forward_only:\n",
        "                attention_states = tf.transpose(self.encoder_output, [1, 0, 2])\n",
        "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
        "                    self.num_hidden * 2, attention_states, memory_sequence_length=self.X_len, normalize=True)\n",
        "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
        "                                                                   attention_layer_size=self.num_hidden * 2)\n",
        "                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
        "                initial_state = initial_state.clone(cell_state=self.encoder_state)\n",
        "                helper = tf.contrib.seq2seq.TrainingHelper(self.decoder_emb_inp, self.decoder_len, time_major=True)\n",
        "                decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, helper, initial_state)\n",
        "                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True, scope=decoder_scope)\n",
        "                self.decoder_output = outputs.rnn_output\n",
        "                self.logits = tf.transpose(\n",
        "                    self.projection_layer(self.decoder_output), perm=[1, 0, 2])\n",
        "                self.logits_reshape = tf.concat(\n",
        "                    [self.logits, tf.zeros([self.batch_size, summary_max_len - tf.shape(self.logits)[1], self.vocabulary_size])], axis=1)\n",
        "            else:\n",
        "                tiled_encoder_output = tf.contrib.seq2seq.tile_batch(\n",
        "                    tf.transpose(self.encoder_output, perm=[1, 0, 2]), multiplier=self.beam_width)\n",
        "                tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(self.encoder_state, multiplier=self.beam_width)\n",
        "                tiled_seq_len = tf.contrib.seq2seq.tile_batch(self.X_len, multiplier=self.beam_width)\n",
        "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
        "                    self.num_hidden * 2, tiled_encoder_output, memory_sequence_length=tiled_seq_len, normalize=True)\n",
        "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(decoder_cell, attention_mechanism,\n",
        "                                                                   attention_layer_size=self.num_hidden * 2)\n",
        "                initial_state = decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size * self.beam_width)\n",
        "                initial_state = initial_state.clone(cell_state=tiled_encoder_final_state)\n",
        "                decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
        "                    cell=decoder_cell,\n",
        "                    embedding=self.embeddings,\n",
        "                    start_tokens=tf.fill([self.batch_size], tf.constant(2)),\n",
        "                    end_token=tf.constant(3),\n",
        "                    initial_state=initial_state,\n",
        "                    beam_width=self.beam_width,\n",
        "                    output_layer=self.projection_layer\n",
        "                )\n",
        "                outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "                    decoder, output_time_major=True, maximum_iterations=summary_max_len, scope=decoder_scope)\n",
        "                self.prediction = tf.transpose(outputs.predicted_ids, perm=[1, 2, 0])\n",
        "\n",
        "        with tf.name_scope(\"loss\"):\n",
        "            if not forward_only:\n",
        "                crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                    logits=self.logits_reshape, labels=self.decoder_target)\n",
        "                weights = tf.sequence_mask(self.decoder_len, summary_max_len, dtype=tf.float32)\n",
        "                self.loss = tf.reduce_sum(crossent * weights / tf.to_float(self.batch_size))\n",
        "\n",
        "                params = tf.trainable_variables()\n",
        "                gradients = tf.gradients(self.loss, params)\n",
        "                clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
        "                optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "                self.update = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=self.global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIx7QRIPvoJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "63ce8d51-c335-4967-c6ab-b828aa97965b"
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Nov 26 23:47:16 2018\n",
        "\n",
        "@author: muvaiz\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "start = time.perf_counter()\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "#from model import Model\n",
        "#from utils import build_dict, build_dataset, batch_iter\n",
        "\n",
        "# Uncomment next 2 lines to suppress error and Tensorflow info verbosity. Or change logging levels\n",
        "# tf.logging.set_verbosity(tf.logging.FATAL)\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "class Simulate_Arguments():\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.num_hidden=150\n",
        "    self.num_layers=2\n",
        "    self.beam_width=10\n",
        "    self.glove=True\n",
        "    self.embedding_size=300\n",
        "    \n",
        "    self.learning_rate=1e-3\n",
        "    self.batch_size=64\n",
        "    self.num_epochs=10\n",
        "    self.keep_prob=0.8\n",
        "    \n",
        "    self.toy=True\n",
        "    self.with_model=False\n",
        "\n",
        "'''def add_arguments(parser):\n",
        "    parser.add_argument(\"--num_hidden\", type=int, default=150, help=\"Network size.\")\n",
        "    parser.add_argument(\"--num_layers\", type=int, default=2, help=\"Network depth.\")\n",
        "    parser.add_argument(\"--beam_width\", type=int, default=10, help=\"Beam width for beam search decoder.\")\n",
        "    parser.add_argument(\"--glove\", action=\"store_true\", help=\"Use glove as initial word embedding.\")\n",
        "    parser.add_argument(\"--embedding_size\", type=int, default=300, help=\"Word embedding size.\")\n",
        "\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3, help=\"Learning rate.\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size.\")\n",
        "    parser.add_argument(\"--num_epochs\", type=int, default=10, help=\"Number of epochs.\")\n",
        "    parser.add_argument(\"--keep_prob\", type=float, default=0.8, help=\"Dropout keep prob.\")\n",
        "\n",
        "    parser.add_argument(\"--toy\", action=\"store_true\", help=\"Use only 50K samples of data\")\n",
        "\n",
        "    parser.add_argument(\"--with_model\", action=\"store_true\", help=\"Continue from previously saved model\")\n",
        "\n",
        "'''\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#add_arguments(parser)\n",
        "#args = parser.parse_args()\n",
        "args=Simulate_Arguments()\n",
        "\n",
        "with open(\"args.pickle\", \"wb\") as f:\n",
        "    pickle.dump(args, f)\n",
        "\n",
        "if not os.path.exists(\"saved_model_1\"):\n",
        "    os.mkdir(\"saved_model_1\")\n",
        "else:\n",
        "    if args.with_model:\n",
        "        old_model_checkpoint_path = open('saved_model/checkpoint', 'r')\n",
        "        old_model_checkpoint_path = \"\".join([\"saved_model/\",old_model_checkpoint_path.read().splitlines()[0].split('\"')[1] ])\n",
        "\n",
        "\n",
        "print(\"Building dictionary...\")\n",
        "word_dict, reversed_dict, article_max_len, summary_max_len = build_dict(\"train\", args.toy)\n",
        "print(\"Loading training dataset...\")\n",
        "train_x, train_y = build_dataset(\"train\", word_dict, article_max_len, summary_max_len, args.toy)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    model = Model(reversed_dict, article_max_len, summary_max_len, args)\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver = tf.train.Saver(tf.global_variables())\n",
        "    if 'old_model_checkpoint_path' in globals():\n",
        "        print(\"Continuing from previous trained model:\" , old_model_checkpoint_path , \"...\")\n",
        "        saver.restore(sess, old_model_checkpoint_path )\n",
        "\n",
        "    batches = batch_iter(train_x, train_y, args.batch_size, args.num_epochs)\n",
        "    num_batches_per_epoch = (len(train_x) - 1) // args.batch_size + 1\n",
        "\n",
        "    print(\"\\nIteration starts.\")\n",
        "    print(\"Number of batches per epoch :\", num_batches_per_epoch)\n",
        "    for batch_x, batch_y in batches:\n",
        "        batch_x_len = list(map(lambda x: len([y for y in x if y != 0]), batch_x))\n",
        "        batch_decoder_input = list(map(lambda x: [word_dict[\"<s>\"]] + list(x), batch_y))\n",
        "        batch_decoder_len = list(map(lambda x: len([y for y in x if y != 0]), batch_decoder_input))\n",
        "        batch_decoder_output = list(map(lambda x: list(x) + [word_dict[\"</s>\"]], batch_y))\n",
        "\n",
        "        batch_decoder_input = list(\n",
        "            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_input))\n",
        "        batch_decoder_output = list(\n",
        "            map(lambda d: d + (summary_max_len - len(d)) * [word_dict[\"<padding>\"]], batch_decoder_output))\n",
        "\n",
        "        train_feed_dict = {\n",
        "            model.batch_size: len(batch_x),\n",
        "            model.X: batch_x,\n",
        "            model.X_len: batch_x_len,\n",
        "            model.decoder_input: batch_decoder_input,\n",
        "            model.decoder_len: batch_decoder_len,\n",
        "            model.decoder_target: batch_decoder_output\n",
        "        }\n",
        "\n",
        "        _, step, loss = sess.run([model.update, model.global_step, model.loss], feed_dict=train_feed_dict)\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            print(\"step {0}: loss = {1}\".format(step, loss))\n",
        "\n",
        "        if step % num_batches_per_epoch == 0:\n",
        "            hours, rem = divmod(time.perf_counter() - start, 3600)\n",
        "            minutes, seconds = divmod(rem, 60)\n",
        "            saver.save(sess, \"./saved_model/model.ckpt\", global_step=step)\n",
        "            print(\" Epoch {0}: Model is saved.\".format(step // num_batches_per_epoch),\n",
        "            \"Elapsed: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds) , \"\\n\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Building dictionary...\n",
            "Loading training dataset...\n",
            "Loading Glove vectors...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-eb240114a055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marticle_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-9e90498536bf>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reversed_dict, article_max_len, summary_max_len, args, forward_only)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mforward_only\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglove\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0minit_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_init_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0minit_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    414\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DY59eZ0FdEGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "afd7ff40-39ba-4b39-bf98-fa340a8146ad"
      },
      "cell_type": "code",
      "source": [
        "isinstance(get_init_embedding(reversed_dict,300), (np.ndarray, np.generic))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove vectors...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "fWwV4rAQXM0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3da50dae-3da4-42a5-c70c-df6668cdff98"
      },
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d48kt6nFZvyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "a8779514-ba9e-45ea-ec32-b220e11801bd"
      },
      "cell_type": "code",
      "source": [
        "(get_init_embedding(reversed_dict,300)).astype(tf.object.as_numpy_dtype)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove vectors...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-da3f6ca36eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mget_init_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'object'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_SzyEh_aw2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "533b5dd1-90d4-4111-95cc-deaaf8636969"
      },
      "cell_type": "code",
      "source": [
        "print(get_init_embedding(reversed_dict,300).shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove vectors...\n",
            "(17212,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MxvknBOPbEqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "b5fcde15-ebb9-4e4b-d4da-7b8f0739165c"
      },
      "cell_type": "code",
      "source": [
        "print(get_init_embedding(reversed_dict,300)[100])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove vectors...\n",
            "[ 0.40545   0.43805   0.36237   0.25683   0.38254   0.68255  -0.97853\n",
            "  0.12741  -0.46129  -0.54809  -0.35384  -0.56697  -0.65756   0.50184\n",
            "  0.53248  -0.77956  -0.089944 -0.37572  -1.1097   -0.30734  -0.022657\n",
            "  0.11632   0.67704  -0.051499 -0.59719  -1.02      0.24289  -0.60216\n",
            " -0.35183  -0.54053   3.9844    0.41521   0.040419  0.26909   1.1193\n",
            "  0.52924   0.37308   0.28924  -0.14714   0.23566  -0.72709   0.053276\n",
            "  0.45373   0.20374  -0.13384   0.015313 -0.22037  -0.15662  -0.30289\n",
            " -0.77536 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZM6XsacaVt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(reversed_dict.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}